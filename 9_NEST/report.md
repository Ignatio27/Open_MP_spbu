## **Описание эксперимента**

В работе исследуется эффективность **вложенного параллелизма OpenMP** на задаче поиска значения

\[
y = \max_i \min_j a_{ij}
\]

то есть для каждой строки матрицы вычисляется минимум по столбцу, после чего берётся максимум среди полученных минимумов. 

Рассматривались два варианта распараллеливания:

1. **Outer-only (mode=outer)** — параллелизация только по строкам (внешний цикл).
2. **Nested (mode=nested)** — параллелизация по строкам с дополнительным распараллеливанием внутреннего цикла по столбцам.

Параметры эксперимента:

- размеры матрицы: **500×500**, **1000×1000**, **2000×2000**;
- число потоков: **1, 2, 4, 8, 16, 32**;
- режим распределения итераций: **static**, **dynamic**, **guided**;
- для nested дополнительно варьировалось число потоков на внутреннем уровне (`inner_threads`), включая значения больше 1.

Для обоих вариантов строились графики:

- времени выполнения и ускорения **для каждого размера матрицы**;
- усреднённые по размерам графики времени и ускорения в зависимости от числа потоков и режима `schedule`.

---

## **Суть решения**

Задача сводится к обработке двумерного массива: каждая строка матрицы обрабатывается независимо от остальных, а внутри строки выполняется последовательный обход по столбцам с операциями сравнения.

### **Последовательная реализация**

В базовом (последовательном) варианте программа проходит по всем строкам матрицы, для каждой строки находит минимальный элемент, после чего обновляет глобальный максимум:

double global_max = -INF;
for (int i = 0; i < nrows; ++i) {
double row_min = +INF;
for (int j = 0; j < ncols; ++j)
row_min = std::min(row_min, a[i*ncols + j]);
global_max = std::max(global_max, row_min);
}


Здесь весь объём работы выполняется в одном потоке, что используется как эталон для расчёта ускорения.

---

### **Параллельная реализация outer-only**

В варианте **outer-only** параллелизуется только внешний цикл по строкам. Каждой строке сопоставляется отдельная итерация параллельного цикла, а итоговый максимум по строкам считается с помощью редукции:

double global_max = -INF;

#pragma omp parallel for reduction(max: global_max) schedule(SCHED)
for (int i = 0; i < nrows; ++i) {
double row_min = +INF;
for (int j = 0; j < ncols; ++j)
row_min = std::min(row_min, a[i*ncols + j]);
global_max = std::max(global_max, row_min);
}


Такой подход создаёт **один** параллельный регион на весь проход по строкам, хорошо загружает потоки и даёт понятное масштабирование по числу строк.

---

### **Параллельная реализация с вложенным параллелизмом (nested)**

В варианте **nested** внешний цикл по строкам также распараллелен, но внутри каждой строки дополнительно создаётся параллельный регион для цикла по столбцам:

double global_max = -INF;

#pragma omp parallel for reduction(max: global_max) schedule(SCHED)
for (int i = 0; i < nrows; ++i) {
double row_min = +INF;
#pragma omp parallel for reduction(min: row_min) schedule(SCHED)
for (int j = 0; j < ncols; ++j)
row_min = std::min(row_min, a[i*ncols + j]);
global_max = std::max(global_max, row_min);
}


Идея состоит в том, чтобы задействовать больше потоков за счёт двух уровней параллелизма (по строкам и по столбцам одновременно). На практике это приводит к множественным созданиям внутренних параллельных регионов и росту накладных расходов, особенно при `inner_threads > 1`.

---

## **Анализ результатов**

### **1. Усреднённые результаты по всем размерам**

На усреднённых графиках (mean time / mean speedup) хорошо видно, что **outer-only** демонстрирует ожидаемое ускорение с ростом числа потоков, тогда как **nested** либо почти не ускоряет, либо даже замедляет программу.

- Среднее ускорение outer-only монотонно растёт и при 8–16 потоках достигает множителей **около 4–6×** относительно последовательного варианта.
- Для nested среднее ускорение остаётся в районе **0.6–1.1×** и практически не улучшается при добавлении потоков, а при включении внутреннего уровня (`inner_threads > 1`) резко падает ниже 1.

Причины такого поведения:

- outer-only использует один длительный параллельный регион и минимизирует накладные расходы;
- nested создаёт множество внутренних параллельных регионов, что даёт большой overhead, а дополнительный уровень параллелизма не успевает окупиться на сравнительно простых операциях сравнения.

---

### **2. Поведение на конкретных размерностях**

#### **500×500 (малый размер)**

Для небольших матриц **доля накладных расходов особенно велика**.

- outer-only уже даёт заметное ускорение: при 8–16 потоках время исполнения сокращается по сравнению с последовательным вариантом в несколько раз.
- nested почти всегда проигрывает outer-only, а при `inner_threads > 1` время выполнения может вырастать на порядок и более из-за стоимости многократного запуска внутренних регионов.

Вывод: на малых задачах вложенный параллелизм **практически всегда вреден**, так как объём полезной работы на каждую строку слишком мал для окупаемости второго уровня распараллеливания.

---

#### **1000×1000 и 2000×2000 (средние и крупные размеры)**

С ростом размера матрицы полезная работа увеличивается, и outer-only масштабируется **ещё лучше**.

- Для размеров 1000×1000 и 2000×2000 outer-only при 8–16 потоках даёт ускорение **до 5–6×** в зависимости от режима `schedule`.
- Nested в лучшем случае приближается к outer-only, когда по сути превращается в однорежимный вариант (по строкам) — то есть при `inner_threads = 1`, когда внутренний цикл фактически выполняется последовательно.

При реальном включении вложенного параллелизма (`inner_threads > 1`) наблюдается:

- падение ускорения до значений **существенно ниже 1**, вплоть до многократного замедления относительно последовательного кода;
- эффект **oversubscription** — суммарное число потоков outer×inner превышает число аппаратных ядер, что приводит к частым переключениям контекста и простоям.

---

### **3. Влияние режима schedule**

Для outer-only различия между `static`, `dynamic` и `guided` невелики: все три схемы дают близкое время выполнения, с небольшим преимуществом `guided` и `dynamic` на крупных матрицах и большом числе потоков.

В nested-варианте выбор `schedule` практически **не меняет общую картину**:

- основное ограничение — накладные расходы на вложенные регионы и переизбыточное число потоков;
- даже при “подборе” сочетаний `schedule` и `inner_threads` nested остаётся ощутимо хуже outer-only по времени и ускорению.

---

## **Итоги**

### **1. Эффективность outer-only**

- Параллелизация только внешнего цикла даёт **стабильное ускорение** во всём диапазоне размеров матриц и числа потоков.
- При 8–16 потоках достигается ускорение **до 4–6×** относительно последовательной версии, при этом зависимость от `schedule` умеренная, а поведение — предсказуемое.

### **2. Эффективность nested параллелизма**

- Вложенный параллелизм оказывается **неэффективным**: при реальном использовании `inner_threads > 1` время выполнения резко растёт, а ускорение падает ниже 1.
- При `inner_threads = 1` nested фактически деградирует к outer-only с лишними накладными расходами и потому редко выигрывает даже в этом режиме.

### **3. Общий вывод**

Для задачи вычисления \(y = \max_i \min_j a_{ij}\) **оптимальной стратегией распараллеливания является outer-only по строкам**, без использования вложенного параллелизма.

Результаты показывают, что:

- добавление второго уровня параллельности **не гарантирует ускорения**;
- на простых, почти **memory-bound** ядрах (чтение и сравнение элементов матрицы) вложенный OpenMP-параллелизм создаёт больше накладных расходов, чем полезной работы.

Таким образом, эксперимент наглядно демонстрирует, что при проектировании параллельных программ важно не только “максимально распараллелить” вычисления, но и учитывать стоимость управления потоками и характер нагрузки.
